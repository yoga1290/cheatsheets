{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![install](\n",
    "https://anaconda.org/yoga1290/pytorch/badges/installer/ipynb.svg)](https://anaconda.org/yoga1290/pytorch/notebook) [![downloads](https://anaconda.org/yoga1290/pytorch/badges/downloads.svg)](https://anaconda.org/yoga1290/pytorch/notebook) [![Anaconda Cloud](\n",
    "https://anaconda.org/yoga1290/pytorch/badges/version.svg)](https://anaconda.org/yoga1290/pytorch/notebook)\n",
    "# NOTE: WIP, visit me later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "+ [Setup](#Environment-setup)\n",
    "+ **Training**: adjust W & b\n",
    "    + Initialization\n",
    "        + [Dataset & DataLoader](#Dataset)\n",
    "        + **Ecoph**: iteration in the training phase\n",
    "    + Forward Propagation\n",
    "        + [Model](#Models)\n",
    "            + **in_features**: size of W\n",
    "            + **out_features**: classes\n",
    "            + Linear Classifiers: returns positive & negative values\n",
    "            + Logistic Regression: returns [0 - 1] values\n",
    "            + Threshold function: returns either 0 or 1 \n",
    "            + [Linear Regression](#Linear-Regression)\n",
    "            + **Weight Initialization**\n",
    "                + Zeros\n",
    "                    + the derivative with respect to loss function is the same for every w; similar to linear model [read me](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94)\n",
    "                + **Xavier initialization** [see](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94)\n",
    "                    + Tanh\n",
    "                + He/Kaiming uniform initialization\n",
    "                    + ReLU\n",
    "                + Uniform distribution\n",
    "                + Normal distribution\n",
    "                    + Vanishing gradients\n",
    "                    + Exploding gradients\n",
    "                        + \"This may result in oscillating around the minima or even overshooting the optimum again and again and the model will never learn\" [see](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94)\n",
    "        + Activation functions:\n",
    "            + Tanh\n",
    "                + zero centered [-1, 1]\n",
    "                + **Xavier initialization** [see](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94)\n",
    "                + Vanishing gradient\n",
    "            + Sigmoid\n",
    "                + [0, 1]\n",
    "                + Initialization\n",
    "                + Vanishing gradient\n",
    "                + **Binary** classification\n",
    "            + ReLU\n",
    "                + [0, 1]\n",
    "                + \"With RELU(z) vanishing gradients are generally not a problem as the gradient is 0 for negative (and zero) inputs and 1 for positive inputs.\" [read me](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94)\n",
    "            + Softmax\n",
    "                + **Multi-class** classification\n",
    "                \n",
    "    + **Loss/Cost**: the difference between the prediected values,\n",
    "        $\\hat{y}$ and true labels, $y$\n",
    "        + [Derivative](#Derivative)\n",
    "        + [Mean Square Error](#Mean-Square-Error)\n",
    "        + [Binary Cross Entropy](#Binary-Cross-Entropy)\n",
    "        + [Cross Entropy](#Cross-Entropy)\n",
    "            + **Multi-class** \"This criterion expects a class index (0 to C-1) as the target for each value\" [PyTorch](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)\n",
    "    + **Backward propagation**:    \n",
    "        + **Optimization**: updates W & b in the Backward propagation\n",
    "            + [Adam optimizer](#Adam)\n",
    "            + Gradient Descent Optimization\n",
    "                + Batch Gradient Descent\n",
    "                + Mini-Batch Gradient Descent (PyTorch's **default**)\n",
    "                + Stochastic Gradient Descent\n",
    "                    + Update loss by one sample at a time\n",
    "                    + Sudden increases may occur\n",
    "                    + May not be accurate\n",
    "                    + Good for big data\n",
    "+ **Validation**: adjust the hyper-parameters; learning rate & batch size\n",
    "    + **Early Stopping**:\n",
    "        + \"Stop training when a monitored quantity has stopped improving\" [[tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)]\n",
    "        + or validation error just got worse\n",
    "\n",
    "+ Tools & Libraries\n",
    "    + **Visualization**\n",
    "        + Pandas\n",
    "        + Matplotlib\n",
    "    + [Numpy](#NumPy)\n",
    "+ Cheatsheets\n",
    "    + [ml-cheatsheet.readthedocs.io](https://ml-cheatsheet.readthedocs.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "\n",
    "## Install\n",
    "+ Install [Anaconda](https://www.anaconda.com/download/#linux)\n",
    "+ Expose `~/anaconda3/bin` (where `conda` executable biniary)\n",
    "+ Install [PyTorch](https://pytorch.org/): `conda install pytorch torchvision -c pytorch`\n",
    "\n",
    "## Online tools\n",
    "+ [Google Colaboratory](https://colab.research.google.com) [[open me!](https://colab.research.google.com/github/yoga1290/cheatsheets/blob/master/PyTorch.ipynb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Optimization\n",
    "\n",
    "+ [PUML](https://raw.githubusercontent.com/yoga1290/cheatsheets/master/gradient-descent.puml)\n",
    "![Gradient Descent](https://github.com/yoga1290/cheatsheets/raw/master/gradient-descent.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import arange, randn\n",
    "\n",
    "# https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel#dataset\n",
    "class MyDataset(Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.x = arange(-3, 3, 0.1).view(-1, 1)\n",
    "        self.f = 1 * self.x - 1\n",
    "        self.y = self.f + 0.1 * randn(self.x.size())\n",
    "        self.len = self.x.shape[0]\n",
    "        \n",
    "    # Getter\n",
    "    def __getitem__(self,index):    \n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "dataLoader = DataLoader(MyDataset(), **params)\n",
    "\n",
    "# for X, y in dataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prebuilt dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "dataset = dsets.MNIST(\n",
    "    root = './data2', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "def show_data(data_sample, shape = (28, 28)):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1].item()))\n",
    "\n",
    "show_data(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchvision Transforms\n",
    "\n",
    "+ Compose\n",
    "+ CenterCrop\n",
    "+ ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "croptensor_data_transform = Compose([\n",
    "    CenterCrop(20),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# set train = false for validation\n",
    "dataset = dsets.MNIST(root = './data', train = False, download = True, transform = croptensor_data_transform)\n",
    "print(\"The shape of the first element in the first tuple: \", dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "![source: https://youtu.be/zJSY2C9xzoU](https://github.com/yoga1290/cheatsheets/raw/4346bd63cf490d978cee156497db3b64f87fc37e/resources/nn-3.3.2-zJSY2C9xzoU.png)\n",
    "![source: https://youtu.be/zJSY2C9xzoU](https://github.com/yoga1290/cheatsheets/raw/4346bd63cf490d978cee156497db3b64f87fc37e/resources/nn-3.3.2-2-zJSY2C9xzoU.png)\n",
    "![source: https://youtu.be/xR4Ian1UIGM](https://github.com/yoga1290/cheatsheets/raw/4346bd63cf490d978cee156497db3b64f87fc37e/resources/nn2-xR4Ian1UIGM.png)\n",
    "> sources [[1](https://youtu.be/xR4Ian1UIGM)] [[2](https://youtu.be/xR4Ian1UIGM)] [[3](https://youtu.be/xR4Ian1UIGM)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.nn.[Model](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Linear, Dropout\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "# Customize Linear Regression Class\n",
    "class linear_regression(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        # Inherit from parent\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = Linear(in_features, out_features, bias=True) #TODO\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "+ Batch Normalization\n",
    "    + Remove Dropout\n",
    "    + Reduce Internal Covariate Shift\n",
    "    + Increase learning rate\n",
    "    + Bias is not necessary\n",
    "    + USE `model.eval()` before perdication (`yhat`)\n",
    "+ Dropout\n",
    "    + USE `model.train()` before training\n",
    "    + USE `model.eval()` before perdication (`yhat`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.init.kaiming_uniform_(linear.weight,nonlinearity='relu')\n",
    "# https://labs.cognitiveclass.ai/tools/jupyterlab/lab/tree/labs/DL0110EN/5.1.2.He_Initialization.ipynb\n",
    "# https://labs.cognitiveclass.ai/tools/jupyterlab/lab/tree/labs/DL0110EN/5.3.1BachNorm.ipynb\n",
    "\n",
    "from torch.nn import Module, ModuleList, Linear, Dropout, BatchNorm1d\n",
    "from torch.nn.init import kaiming_uniform_, xavier_uniform_\n",
    "from torch.nn.functional import relu, tanh\n",
    "\n",
    "class Net(Module):\n",
    "    # Constructor\n",
    "    # in_features = len(W)\n",
    "    def __init__(self,Layers, p=0):\n",
    "        # Inherit from parent\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden = ModuleList()\n",
    "        self.drop = Dropout(p=p)\n",
    "\n",
    "        for input_size,output_size in zip(Layers,Layers[1:]):\n",
    "            linear = Linear(input_size,output_size)\n",
    "            \n",
    "            # Uniform initialization\n",
    "            #linear.weight.data.uniform_(0, 1)\n",
    "            \n",
    "            # He/Kaiming uniform initialization\n",
    "            #kaiming_uniform_(linear.weight, nonlinearity='relu')\n",
    "            \n",
    "            # Xavier initialization\n",
    "            #xavier_uniform_(linear.weight)\n",
    "            \n",
    "            self.hidden.append( linear )\n",
    "            \n",
    "            # Batch Normalization\n",
    "            # self.hidden.append( BatchNorm1d(output_size) )\n",
    "            \n",
    "            # Dropout\n",
    "            # self.hidden.append( Dropout(p=p) )\n",
    "\n",
    "    # Prediction function\n",
    "    # https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward\n",
    "    def forward(self,x):\n",
    "        L=len(self.hidden)\n",
    "        for (l, linear_transform)  in zip(range(L),self.hidden):\n",
    "            if l<L-1:\n",
    "                x = relu(linear_transform (x))\n",
    "                #x = tanh(linear_transform (x))\n",
    "                #x = self.drop(x)\n",
    "            # last layer\n",
    "            else:\n",
    "                x =linear_transform (x)\n",
    "        \n",
    "        return x #yhat\n",
    "    \n",
    "    #def activation(self,x):\n",
    "    #    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, Sigmoid\n",
    "\n",
    "model = Sequential( Linear(2,1), Sigmoid() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state_dict(), load_state_dict(dict), save & load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save\n",
    "from torch import load\n",
    "from torch.nn import Module, Linear\n",
    "\n",
    "save({\"a\": 123}, 'tmp.pt')\n",
    "tdict = load('tmp.pt')\n",
    "print(tdict)\n",
    "\n",
    "model = Linear(5, 1)\n",
    "save(model.state_dict(), 'model.pt')\n",
    "model.load_state_dict( load('model.pt') )\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import linspace, tensor\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "x = linspace(-3, 3, 100, requires_grad = True)\n",
    "Y = relu(x)\n",
    "\n",
    "z = tensor([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
    "relu(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criterion/Cost/Loss\n",
    "\n",
    "Comparing/differentiating the prediected values (**Y^**) and the actual labels (**Y**)\n",
    "\n",
    "### Mean Square Error\n",
    "\n",
    "+ [torch.nn.MSELoss(size_average=None, reduce=None, reduction='elementwise_mean')](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "\n",
    "criterion = MSELoss()\n",
    "\n",
    "# equivalent to:\n",
    "from torch import mean\n",
    "\n",
    "def criterion(yhat, y):\n",
    "    return mean((yhat - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss\n",
    "\n",
    "criterion = BCELoss()\n",
    "\n",
    "# equivalent to:\n",
    "from torch import mean\n",
    "from torch import log\n",
    "\n",
    "def criterion(yhat, y):\n",
    "    return -1 * mean(y * log(yhat) + (1-y) * log(1 - yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "# https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "\n",
    "criterion = CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "\n",
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "opt = Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train([true]) # sets model.training = true\n",
    "\n",
    "# https://labs.cognitiveclass.ai/tools/jupyterlab/lab/tree/labs/DL0110EN/5.1.1Xaviermist1layer.ipynb\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(model,criterion, train_loader,validation_loader, optimizer, epochs=100):\n",
    "    i=0\n",
    "    useful_stuff={'training_loss':[],'validation_accuracy':[]}  \n",
    "    \n",
    "    #n_epochs\n",
    "    for epoch in range(epochs):\n",
    "        for i,(x, y) in enumerate(train_loader):\n",
    "\n",
    "            #clear gradient \n",
    "            optimizer.zero_grad()\n",
    "            #make a prediction logits \n",
    "            z=model(x.view(-1,28*28))\n",
    "            # calculate loss \n",
    "            loss=criterion(z,y)\n",
    "    \n",
    "            # calculate gradients of parameters \n",
    "            loss.backward()\n",
    "            # update parameters \n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.data.item())\n",
    "        correct=0\n",
    "        for x, y in validation_loader:\n",
    "            #perform a prediction on the validation  data  \n",
    "            yhat= model(x.view(-1,28*28))\n",
    "            \n",
    "            _,lable=torch.max(yhat,1)\n",
    "            correct+=(lable==y).sum().item()\n",
    " \n",
    "    \n",
    "        accuracy=100*(correct/len(validation_dataset))\n",
    "   \n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "    \n",
    "    return useful_stuff\n",
    "\n",
    "train_dataset=dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "validation_dataset=dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "train_loader= DataLoader(dataset=train_dataset,batch_size=2000,shuffle=True)\n",
    "validation_loader= DataLoader(dataset=validation_dataset,batch_size=5000,shuffle=False)\n",
    "\n",
    "criterion= CrossEntropyLoss()\n",
    "model= Net(layers)\n",
    "optimizer= SGD(model.parameters(),lr=learning_rate) # momentum=0.4)\n",
    "\n",
    "learning_rate=0.01\n",
    "training_results=train(model,criterion, train_loader,validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Convolution](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)\n",
    "\n",
    "<img src = \"https://ibm.box.com/shared/static/wq8wbqhm4824y1oxpdbol55q645gykg9.gif\" width = 500, align = \"center\">\n",
    "\n",
    "> source: [cognitiveclass.ai](https://labs.cognitiveclass.ai/tools/jupyterlab/lab/tree/labs/DL0110EN/6.1.1What%20is%20Convolution.ipynb)\n",
    "\n",
    "+ [MaxPool2d](https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d)\n",
    "+ kernels count = **in_channels**\n",
    "+ 1 bais\n",
    "\n",
    "+ [Algorithmia](https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d\n",
    "from torch import tensor\n",
    "\n",
    "conv1 = Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=3)\n",
    "conv1.state_dict()['weight'][0][0] = tensor([[1.0,1.0],[1.0,1.0]])\n",
    "conv1.state_dict()['bias'][0] = 0.0\n",
    "conv1.state_dict()\n",
    "\n",
    "z1 = conv1(image1)\n",
    "\n",
    "print(\"z4:\",z4)\n",
    "print(\"z4:\",z4.shape[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy\n",
    "\n",
    "#### [linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linspace.html)\n",
    "+ Return evenly spaced numbers over a specified interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import arange\n",
    "from numpy import linspace\n",
    "\n",
    "print( linspace(-2, 2 ,5) )\n",
    "print( arange(-2, 2 ,5).numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [array([]).T](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.ndarray.T.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "x = array([[1,2,3], [4, 5, 6]])\n",
    "print(x)\n",
    "print(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.meshgrid.html\n",
    "# https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.c_.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "#### torch.tensor( , [requires_grad=True, dtype=torch.int8|uint8|int16/short|half|float|int|double|long, device=cuda0])\n",
    "+ .zeros()\n",
    "+ .ones()\n",
    "+ .pow(2)\n",
    "+ .sum()\n",
    "+ .ndimension()\n",
    "+ .numpy()\n",
    "+ .shape\n",
    "+ .dtype\n",
    "+ [begin_row **\\:** end_row **\\,** begin_column **\\:** end_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import ones\n",
    "from torch import zeros\n",
    "\n",
    "print(zeros((2,)))\n",
    "print(ones((2,2)).numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False).view()](https://pytorch.org/docs/stable/torch.html#torch.arange)\n",
    "\n",
    "+ [reshape(input, shape)](https://pytorch.org/docs/stable/torch.html#torch.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import arange\n",
    "from torch import reshape\n",
    "\n",
    "print( arange(-2, 2, 1) ) # 1 Row\n",
    "\n",
    "print( arange(-2, 2, 1).view(-1, 1) ) # 1 Column\n",
    "print( reshape(arange(-2, 2, 1), (-1, 1)) ) # same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save\n",
    "from torch import load\n",
    "\n",
    "save({\"a\": 123}, 'tmp.pt')\n",
    "tdict = load('tmp.pt')\n",
    "print(tdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative\n",
    "\n",
    "### Partial derivative w respect to u/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pylab as plt\n",
    "import torch.functional as F\n",
    "\n",
    "# Calculate f(u, v) = v * u + u^2 at u = 1, v = 2\n",
    "\n",
    "u = torch.tensor(1.0,requires_grad=True)\n",
    "v = torch.tensor(2.0,requires_grad=True)\n",
    "f = u * v + u ** 2\n",
    "\n",
    "f.backward()\n",
    "print(\"The result of v * u + u^2: \", f)\n",
    "print(\"The partial derivative with respect to u: \", u.grad)\n",
    "print(\"The partial derivative with respect to v: \", v.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the derivative with multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-10, 10, 10, requires_grad = True)\n",
    "Y = x ** 2\n",
    "y = torch.sum(x ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [scikit](http://www.scikit-learn.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source ~/venv/bin/activate \n",
    "# see https://www.tensorflow.org/install/pip\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "z = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
    "torch.nn.functional.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
